---
title: 第九章.Python编程：IO编程
author: HanamakiX
date: 2022/07/25 12:00:00
categories:
 - Python
tags:
 - 编程
---

**摘要：IO编程**

<!-- more -->

::: warning 警告
**我年纪轻轻就学会了`Python`编程**

**来自：`HanamakiX`**
:::

## **本章目录**

 - **文件读写**
 - **with-as上下文管理器**
 - **StringIO和BytesIO**
 - **操作文件和目录：os.path和pathlib**
 - **序列化**


::: tip 提示
**IO在计算机中指Input/Output，也就是输入和输出。一般就是编程语言对于文件的操作**
:::


## **一、文件读写**


读写文件是最常见的IO操作。Python内置了读写文件的函数：`open`，

读写文件前，我们先必须了解一下，在磁盘上读写文件的功能都是由操作系统提供的，现代操作系统不允许普通的程序直接操作磁盘，

所以，读写文件就是请求操作系统打开一个文件对象（通常称为文件描述符），

然后，通过操作系统提供的接口从这个文件对象中读取数据（读文件），或者把数据写入这个文件对象（写文件）。

常用语法：

```python

f = open('your_file_path', '读写模式', encoding = '文件编码：一般是utf-8')

f.read()：读文件

f.write("line")：写文件

f.close()：关闭文件
```

### **读取文件**


```python
f = open('./examples/1.txt','r',encoding='utf-8')
f.read()



output:

    '这是一个测试文件'
```


```python
f.close()
```


### **写文件**


```python
f = open('./examples/2.txt','w',encoding='utf-8')
f.write('这是第二个测试文件')
f.close()
```


```python
f = open('./examples/2.txt','r',encoding='utf-8')
print(f.read())
f.close()



output:

    这是第二个测试文件
```
    

### **读取文件多行**

- read()：一行一行读取
- readlines()：读取所有行


```python
f = open('./examples/3.txt','w',encoding='utf-8')
f.write('这是第三个测试文件第一行\n')
f.write('这是第三个测试文件第二行')
f.close()
```


```python
f = open('./examples/3.txt','r',encoding='utf-8')
print(f.read())
f.close()



output:

    这是第三个测试文件第一行
    这是第三个测试文件第二行
```    


```python
f = open('./examples/3.txt','r',encoding='utf-8')
print(f.readlines())
f.close()



output:

    ['这是第三个测试文件第一行\n', '这是第三个测试文件第二行']
```


```python
f = open('./examples/3.txt','r',encoding='utf-8')
for x in f.readlines():
    print(x)
f.close()



output:

    这是第三个测试文件第一行
    
    这是第三个测试文件第二行
```    

### **去除每一行末尾的换行符：strip()**


```python
f = open('./examples/3.txt','r',encoding='utf-8')
res = [x.strip() for x in f.readlines()]
print(res)
f.close()



output:
    ['这是第三个测试文件第一行', '这是第三个测试文件第二行']
```


### **open文件的模式组合**

#### **文件格式**

- **t：以文本格式打开文件（默认）。一般用于文本文件，如：txt。**
- **b：以二进制格式打开文件。一般用于非文本文件，如：图片。**


**这一类参数可以与其它的模式参数组合使用，用于指定打开文件的格式。**


#### **读写格式**

- **r：以只读方式打开文件（默认模式）。文件指针定位在文件头的位置。如果文件不存在会报错。**
- **w：以只写方式打开文件。如果文件存在，则打开文件，清空文件内容，从文件头开始编辑；如果文件不存在，则创建新文件，打开编辑。**
- **a：以追加方式打开文件，同样是只写，不允许进行读操作。如果文件存在，则打开文件，将文件指针定位到文件尾。因此，新的内容是追加在已有内容之后。如果文件不存在，则创建新文件进行写入。**
- **+：打开一个文件进行更新（可读写）。注意：该模式不能单独使用，需要与r/w/a组合使用。文件指针的位置取决于另一个组合参数**


#### **组合格式**

- **r+：打开一个文件用于读写。如果文件存在，则打开文件，将文件指针定位在文件头，新写入的内容在原有内容的前面；如果文件不存在会报错。**
- **w+：打开一个文件用于读写。如果文件存在，则打开文件，清空原有内容，进入编辑模式；如果文件不存在，则创建一个新文件进行读写操作。**
- **a+：以追加模式打开一个文件用于读写。如果文件存在，则打开文件，将文件指针定位在文件尾，新写入的内容在原有内容的后面；如果文件不存在，则创建一个新文件用于读写。**


**所有上面这些模式默认都是t——文本模式，如果要以二进制模式打开，需要加上参数b，如：rb、rb+、wb、wb+、ab、ab+。**

#### **常用文件编码**

- **utf-8：unicode，最常用**
- **gbk：汉字扩展**
- **b：二进制**


**需要注意：文件是什么编码就必须要什么编码打开，否则会乱码**


### **Python自动检测文件编码**


```python
f= open('./examples/4.txt', 'r',encoding='utf-8')
text = f.read()
f.close()
print(text)



output:

    ---------------------------------------------------------------------------

    UnicodeDecodeError                        Traceback (most recent call last)

    ~\AppData\Local\Temp/ipykernel_6052/1119216069.py in <module>
          1 f= open('./examples/4.txt', 'r',encoding='utf-8')
    ----> 2 text = f.read()
          3 f.close()
          4 print(text)
    

    D:\anaconda\lib\codecs.py in decode(self, input, final)
        320         # decode input (taking the buffer into account)
        321         data = self.buffer + input
    --> 322         (result, consumed) = self._buffer_decode(data, self.errors, final)
        323         # keep undecoded input until the next call
        324         self.buffer = data[consumed:]
    

    UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 0: invalid continuation byte
```



```python
import chardet

f= open('./examples/4.txt', 'rb')
text = f.read()
print(chardet.detect(text))
f.close()



output:

    {'encoding': 'GB2312', 'confidence': 0.99, 'language': 'Chinese'}
```



```python
f= open('./examples/4.txt', 'r',encoding='GB2312')
text = f.read()
f.close()
print(text)



output:

    这是一个测试编码文件
```


### **追加模式不清空文件**

正常的写：`w`模式打开一个已经存在的文件会把该文件清空，这时候使用追加：`a`，则可以打开该文件不清空


```python
f= open('./examples/5.txt', 'w',encoding='utf-8')
f.write('lines')
f.close()
```


```python
f= open('./examples/5.txt', 'r',encoding='utf-8')
print(f.read())
f.close()



output:

    lines
```


```python
f= open('./examples/5.txt', 'w',encoding='utf-8')
f.write('new lines')
f.close()
```


```python
f= open('./examples/5.txt', 'r',encoding='utf-8')
print(f.read())
f.close()



output:

    new lines
```    


```python
f= open('./examples/5.txt', 'a',encoding='utf-8')
f.write('\nnew new lines')
f.close()
```


```python
f= open('./examples/5.txt', 'r',encoding='utf-8')
print(f.read())
f.close()



output:

    new lines
    new new lines
```


### **以二进制打开文件，使用encode和decode编码转换**


```python
f= open('./examples/6.txt', 'w',encoding='utf-8')
f.write('我是第六个文件')
f.close()
```


```python
f= open('./examples/6.txt', 'rb')
print(f.read())
f.close()



output:

    b'\xe6\x88\x91\xe6\x98\xaf\xe7\xac\xac\xe5\x85\xad\xe4\xb8\xaa\xe6\x96\x87\xe4\xbb\xb6'
```    


```python
f= open('./examples/6.txt', 'rb')
text = f.read()
text = text.decode('utf-8')
f.close()
print(text)



output:

    我是第六个文件
```    


## **二、with-as上下文管理器**


像上文每次open文件都需要close，这样太繁琐了，Python提供：with...as:帮助我们自动调用close，即为：Python上下文管理

```python

with open('./examples/6.txt', 'r', encoding='utf-8') as f:
    text = [x.strip() for x in f]

```


```python
with open('./examples/6.txt', 'r', encoding='utf-8') as f:
    text = [x.strip() for x in f]

print(text)



output:

    ['我是第六个文件']
```    


### **拓展1：自己实现with...as:功能**

这里联系到我们之前介绍的类的魔法方法，当一个类实现：`__enter__`和`__exit__`两个方法就可以实现with...as:功能


```python
class myopen:
    def __init__(self,filepath,mode='r',encoding='utf-8'):
        self.filepath=filepath
        self.mode=mode
        self.encoding=encoding

    def __enter__(self):
        # print('enter')
        self.f=open(self.filepath,mode=self.mode,encoding=self.encoding)
        return self.f

    def __exit__(self, exc_type, exc_val, exc_tb):
        # print('exit')
        self.f.close()

with myopen('./examples/6.txt', 'r', encoding='utf-8') as f:
    text = [x.strip() for x in f]

print(text)        
        


output:

    ['我是第六个文件']
```


### **拓展1：读取超大型文件**

注意到，由于当今社会的数据量越来越大，很多时候比如一个text文件很大，直接打开会出现系统内存报错，这时候我们应该怎么读取呢？

这种时候我们就需要用到Python的生成器功能，回顾一下：生成器到使用时才能产生具体数值

假如我们有个文件：`7.txt` 非常大


```python
"""
直接open会报错
"""


with open('./examples/7.txt', 'r', encoding='utf-8') as f:
    text = [x.strip() for x in f]

print(text)


```


```python
"""
使用生成器就可以读取
"""

import traceback

class ReadBigFile():

    def __init__(self,file):

        self.file=file

    def __iter__(self):

        try:
            with open(self.file,'r',encoding='utf-8') as f:
                for i,j in enumerate(f):
                    yield j.strip()
        except Exception:
            traceback.print_exc()
            
            
for line in ReadBigFile('./examples/7.txt'):
    print(line)
    break
```


## **三、StringIO和BytesIO**


很多时候，数据读写不一定是文件类型，还有可能是内存中读写，这时候就要用到两个函数：StringIO和BytesIO

- **StringIO：内存读写str**

- **BytesIO：内存读写二进制**

**使用：getvalue()获取数据，read，write，readlines和open类似**


```python
from io import StringIO

f = StringIO()
f.write('hello world')        # 11



f.getvalue()                 # 'hello world'



f = StringIO('hello world')
f.readline()                 # 'hello world'




from io import BytesIO

f = BytesIO()
text = '你好'.encode('utf-8')
f.write(text)                  # 6



f.getvalue()                   # b'\xe4\xbd\xa0\xe5\xa5\xbd'



f = BytesIO(b'\xe4\xbd\xa0\xe5\xa5\xbd')
f.read().decode('utf-8')                  #'你好'
```



## **四、操作文件和目录：os.path和pathlib**


一般来说我们操作文件或者目录文件夹，可以在系统对应的终端下执行命令实现，如windows cmd的：dir，linux bash的：ls等

Python也提供了相应的操作函数来执行文件和目录的操作，首先需要说的就是：os模块

### **os**

#### **获取操作系统类型：os.name**


```python
'''
该变量返回当前操作系统的类型
'''

import os

os.name       # 'nt'
              #分别是posix , nt , java， 对应linux/windows/java虚拟机
```  
    

### **也可以通过：sys.platform获取**


```python
import sys

sys.platform     # 'win32'
```


### **获取环境变量**


```python
os.environ
```

### **操作文件和目录**


```python
'''
查看当前目录的绝对路径
'''
os.path.abspath('./')           # 'E:\\notebook\\B站\\花卷学Python\\9. Python编程：IO编程'
```



```python
'''
查看当前目录的上级目录
'''
os.path.dirname('./examples')    # '.'
```



```python
'''
遍历目录
'''

os.listdir('./')                # ['.ipynb_checkpoints', 'examples', 'images', '第九章、Python编程：IO编程.ipynb']
```



```python
'''
遍历目录2
'''

list(os.walk('./'))



output:

    [('./',
      ['.ipynb_checkpoints', 'examples', 'images'],
      ['第九章、Python编程：IO编程.ipynb']),
     ('./.ipynb_checkpoints', [], ['第九章、Python编程：IO编程-checkpoint.ipynb']),
     ('./examples',
      ['.ipynb_checkpoints'],
      ['1.txt', '2.txt', '3.txt', '4.txt', '5.txt', '6.txt', 'dict.pkl']),
     ('./examples\\.ipynb_checkpoints', [], ['1-checkpoint.txt']),
     ('./images', [], [])]
```



```python
'''
拼接两个目录
'''
os.path.join('./','examples')     # './examples'



'''
创建目录
'''
os.mkdir('./path')



'''
创建多层目录
'''
os.makedirs('./path/path1/path2')



'''
删除目录
'''
os.rmdir('./path/path1/path2')



'''
删除多层目录
'''

import shutil

shutil.rmtree('./path')


'''
删除文件
'''
os.remove('./1.txt')



'''
重命名文件
'''
os.rename('./1.txt','./2.txt')



'''
获取文件扩展名
'''
os.path.splitext('./examples/1.txt')     # ('./examples/1', '.txt')



'''
判断是否是文件夹
'''
os.path.isdir('./examples')             # True



'''
判断是否是文件
'''
os.path.isfile('./examples/1.txt')     # True
```


### **更厉害的文件和目录操作：pathlib**


```python
'''
获取当前目录
'''

from pathlib import Path

Path().cwd()                          # WindowsPath('E:/notebook/B站/花卷学Python/9. Python编程：IO编程')



'''
目录拼接
'''

Path('./').joinpath('./examples')     # WindowsPath('examples')



'''
获取目录名字
'''

p = Path().cwd()
p.name                                # '9. Python编程：IO编程'



'''
获取上级
'''

p = Path().cwd()
p.parent                             # WindowsPath('E:/notebook/B站/花卷学Python')



'''
获取文件后缀
'''

Path('./examples/1.txt').suffix      # '.txt'



'''
获取目录下固定格式的文件
'''

p = Path('./examples')

for x in p.glob('*.txt'):
    print(x)


output:

    examples\1.txt
    examples\2.txt
    examples\3.txt
    examples\4.txt
    examples\5.txt
    examples\6.txt
    



p = Path().cwd()
dir(p)



output:

    ['__bytes__',
     '__class__',
     '__class_getitem__',
     '__delattr__',
     '__dir__',
     '__doc__',
     '__enter__',
     '__eq__',
     '__exit__',
     '__format__',
     '__fspath__',
     '__ge__',
     '__getattribute__',
     '__gt__',
     '__hash__',
     '__init__',
     '__init_subclass__',
     '__le__',
     '__lt__',
     '__module__',
     '__ne__',
     '__new__',
     '__reduce__',
     '__reduce_ex__',
     '__repr__',
     '__rtruediv__',
     '__setattr__',
     '__sizeof__',
     '__slots__',
     '__str__',
     '__subclasshook__',
     '__truediv__',
     '_accessor',
     '_cached_cparts',
     '_cparts',
     '_drv',
     '_flavour',
     '_format_parsed_parts',
     '_from_parsed_parts',
     '_from_parts',
     '_hash',
     '_init',
     '_make_child',
     '_make_child_relpath',
     '_opener',
     '_parse_args',
     '_parts',
     '_pparts',
     '_raw_open',
     '_root',
     '_str',
     'absolute',
     'anchor',
     'as_posix',
     'as_uri',
     'chmod',
     'cwd',
     'drive',
     'exists',
     'expanduser',
     'glob',
     'group',
     'home',
     'is_absolute',
     'is_block_device',
     'is_char_device',
     'is_dir',
     'is_fifo',
     'is_file',
     'is_mount',
     'is_relative_to',
     'is_reserved',
     'is_socket',
     'is_symlink',
     'iterdir',
     'joinpath',
     'lchmod',
     'link_to',
     'lstat',
     'match',
     'mkdir',
     'name',
     'open',
     'owner',
     'parent',
     'parents',
     'parts',
     'read_bytes',
     'read_text',
     'readlink',
     'relative_to',
     'rename',
     'replace',
     'resolve',
     'rglob',
     'rmdir',
     'root',
     'samefile',
     'stat',
     'stem',
     'suffix',
     'suffixes',
     'symlink_to',
     'touch',
     'unlink',
     'with_name',
     'with_stem',
     'with_suffix',
     'write_bytes',
     'write_text']
```


### **总结：os和pathlib对照表**


|操作|os and os.path|pathlib|
|---|---|---|
|绝对路径|os.path.abspath|Path.resolve|
|修改权限|os.chmod|Path.chmod|
|创建目录|os.mkdir|Path.mkdir|
|重命名|os.rename|Path.rename|
|移动|os.replace|Path.replace|
|删除目录|os.rmdir|Path.rmdir|
|删除文件|os.remove, os.unlink|Path.unlink|
|工作目录|os.getcwd|Path.cwd|
|是否存在|os.path.exists|Path.exists|
|用户目录|os.path.expanduser|Path.expanduser and Path.home|
|是否为目录|os.path.isdir|Path.is_dir|
|是否为文件|os.path.isfile|Path.is_file|
|是否为连接|os.path.islink|Path.is_symlink|
|文件属性|os.stat|Path.stat, Path.owner, Path.group|
|是否为绝对路径|os.path.isabs|PurePath.is_absolute|
|路径拼接|os.path.join|PurePath.joinpath|
|文件名|os.path.basename|PurePath.name|
|上级目录|os.path.dirname|PurePath.parent|
|同名文件|os.path.samefile|Path.samefile|
|后缀|os.path.splitext|PurePath.suffix|



## **五、序列化**


在程序的运行过程，所有的变量都存储在内存中，一旦程序结束就被系统回收了，下次需要重新运行才行，

为了保存中间的变脸，我们需要把变量从内存变成可存储，这就是序列化，

而把存储的变量重新读写到内存中就是反序列化，

Python提供内置模块：pickle来进行序列化和反序列化

常用方法：

- **pickle.dump：对象序列化到文件**
- **pickle.dumps：对象序列化**
- **pickle.laod：对象从文件中发序列化**
- **pickle.laods：对象发序列化**


```python
a = {'a':1,'b':2}


"""
我们把上面字典序列化
"""
import pickle

pickle.dumps(a)           # '\x80\x04\x95\x11\x00\x00\x00\x00\x00\x00\x00}\x94(\x8c\x01a\x94K\x01\x8c\x01b\x94K\x02u.'




"""
我们把上面字典序列化进行反序列化
"""
import pickle

b = pickle.dumps(a)
print(f'序列化：{b}')
b = pickle.loads(b)
print(f'发序列化：{b}')



output:

    序列化：b'\x80\x04\x95\x11\x00\x00\x00\x00\x00\x00\x00}\x94(\x8c\x01a\x94K\x01\x8c\x01b\x94K\x02u.'
    发序列化：{'a': 1, 'b': 2}
    


"""
我们把上面字典序列化到文件
"""
import pickle

with open('./examples/dict.pkl','wb') as f:
    pickle.dump(a,f)



"""
我们把上面字典序列化文件反序列化到对象
"""
import pickle

with open('./examples/dict.pkl','rb') as f:
    b = pickle.load(f)

print(b)



output:

    {'a': 1, 'b': 2}
```

### **JSON**

一般来说，序列化和反序列化只能在同一种语言中执行，要想在不同语言之间传递对象就必须把对象序列化为标准格式，

比如非常常用的格式：JSON

一般的JSON格式可以转化为Python的字典或者列表格式，两者对应关系如下：

|JSON类型|Python类型|
|---|---|
|{}|dict|
|[]|list|
|"string"|str|
|1234.56|int或float|
|true/false|True/False|
|null|None|

Python提供内置模块：json来处理json格式，json的常用方法和pickle非常类似：

- **json.dump：对象json到文件**
- **json.dumps：对象到json**
- **json.laod：对象从文件中到json**
- **json.laods：json到对象**


```python
a = {'a':1,'b':2}




"""
我们把上面字典序列化
"""
import json

json.dumps(a)       # '{"a": 1, "b": 2}'




"""
我们把上面字典序列化进行反序列化
"""
import json

b = json.dumps(a)
print(f'序列化：{b}')
b = json.loads(b)
print(f'发序列化：{b}')



output:

    序列化：{"a": 1, "b": 2}
    发序列化：{'a': 1, 'b': 2}
    



"""
我们把上面字典序列化到文件
"""
import pickle

with open('./examples/dict.pkl','w',encoding='utf-8') as f:
    json.dump(a,f)



"""
我们把上面字典序列化文件反序列化到对象
"""
import pickle

with open('./examples/dict.pkl','r',encoding='utf-8') as f:
    b = json.load(f)

print(b)       



output:

    {'a': 1, 'b': 2}
    



help(json.dump)


    Help on function dump in module json:
    
    dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)
        Serialize ``obj`` as a JSON formatted stream to ``fp`` (a
        ``.write()``-supporting file-like object).
        
        If ``skipkeys`` is true then ``dict`` keys that are not basic types
        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped
        instead of raising a ``TypeError``.
        
        If ``ensure_ascii`` is false, then the strings written to ``fp`` can
        contain non-ASCII characters if they appear in strings contained in
        ``obj``. Otherwise, all such characters are escaped in JSON strings.
        
        If ``check_circular`` is false, then the circular reference check
        for container types will be skipped and a circular reference will
        result in an ``OverflowError`` (or worse).
        
        If ``allow_nan`` is false, then it will be a ``ValueError`` to
        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)
        in strict compliance of the JSON specification, instead of using the
        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).
        
        If ``indent`` is a non-negative integer, then JSON array elements and
        object members will be pretty-printed with that indent level. An indent
        level of 0 will only insert newlines. ``None`` is the most compact
        representation.
        
        If specified, ``separators`` should be an ``(item_separator, key_separator)``
        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and
        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,
        you should specify ``(',', ':')`` to eliminate whitespace.
        
        ``default(obj)`` is a function that should return a serializable version
        of obj or raise TypeError. The default simply raises TypeError.
        
        If *sort_keys* is true (default: ``False``), then the output of
        dictionaries will be sorted by key.
        
        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the
        ``.default()`` method to serialize additional types), specify it with
        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.
```


## 赞赏

::: tip

**读后若有收获，可以微信请作者喝咖啡：**

<img src="../../images/goodness.jpg"  height="300" width="300" />
:::